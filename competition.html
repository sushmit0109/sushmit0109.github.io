<!DOCTYPE html>
<html lang="en">
  
  <head>
  <meta charset="UTF-8">
  <title>SemEval 2022 Task 11: MultiCoNER </br><b>Multi</b>lingual <b>Co</b>mplex <b>N</b>amed <b>E</b>ntity <b>R</b>ecognition</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="theme-color" content="#157878">
  <link rel="stylesheet" href="/css/normalize.css">
  <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
  <link rel="stylesheet" href="/css/cayman.css">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.6/css/bootstrap.min.css" integrity="sha384-rwoIResjU2yc3z8GV/NPeZWAv56rSmLldC3R/AZzGRnGxQQKnKkoFVhFQhNUwEyJ" crossorigin="anonymous">
    <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-wvfXpqpZZVQGK6TAh5PVlGOfQNHSoD2xbE+QkPxCAFlNEevoEH3Sl0sibVcOQVnN" crossorigin="anonymous">
    
	<!-- Google Analytics -->
	<script>
		(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
		m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

		ga('create', 'UA-204298917-1', 'auto');
		ga('send', 'pageview', {
		  'page': '/competition',
		  'title': 'Competition'
		});
	</script>
	<!-- End Google Analytics -->


</head>

  <body>
    <section class="page-header">
  <h1 class="project-name">SemEval 2022 Task 11: MultiCoNER </br><b>Multi</b>lingual <b>Co</b>mplex <b>N</b>amed <b>E</b>ntity <b>R</b>ecognition</h1>
  <h2 class="project-tagline"></h2>
  <a href="/" class="btn">Welcome</a>  
  <a href="/competition" class="btn">Competition</a>
    <a href="/dataset" class="btn">Dataset</a>
    <a href="/baseline" class="btn">Baseline</a>
  <a href="/organizers" class="btn">Organizers</a>
    <a href="/faq" class="btn">FAQs</a>
    <a href="/results" class="btn">Results</a>
    <a href="/paper" class="btn">Paper Instructions</a>
</section>

    
      
      
<!--      -->
      
      
      
      
      
      
      


    <section class="main-content">
      <div id="side-table-wrapper" style="float:right; width:310px; font-size: small">
          
          <h4 id="side-table-header">Recent Updates</h4><br>
          <div style="background-color: beige">
          <ul>
              <li><b>Feb 8, 2022</b> Please check out <a href="/paper" target="_blank">this page</a> for information on paper submission.</li>
              <li><b>Feb 5, 2022</b> <a href="/results" target="_blank">Rankings</a> are out.</li>
              <li><b>Jan 25, 2022</b> Test phase duration is increased by 2 days. New end date <b>Jan 30 23:59 UTC</b>.</li>
              <li><b>Jan 04, 2022</b> <a href="/faq" target="_blank">FAQs</a> about test phase are answered.</li> 
              <li><b>Oct 28, 2021</b> Submission site on <a href="https://competitions.codalab.org/competitions/36044" target="_blank">Codalab</a> is open now. Register now!</li> 
              <li><b>Oct 25, 2021</b> Updated information on <a href="/competition#:~:text=4.-,Evaluation,-In%20this%20shared" target="_blank">participation and preparing submissions.</a></li> 
              <li><b>Sep 10, 2021</b> A <a href="/baseline" target="_blank">Baseline system</a> with dev set results is available.</li> 
           <li>Join us in <a href="https://join.slack.com/t/multiconer/shared_invite/zt-vi3g97cx-MpqTvS07XX22S78nRC2s0Q" target="_blank">Slack</a>.</li>
              <li><b>Sep 03, 2021</b> <a href="/dataset">Training data</a> is available.</li>
           <li><b>Aug 23, 2021</b> <a href="/competition">Competition</a> page has some trial data.</li>
          </ul>
              </div>
          
        <h4 id="side-table-header">Important Dates</h4>
        <table id="important-dates" class="table table-condensed">
          <tbody>
            <tr><td>Trial Data Ready</td>
              <td>
                
                 <strike> <font color="grey">
                
                Jul 31 (Sat), 2021
              </td>
            </tr>
            <tr><td>Training Data Ready</td>
              <td>
                 <strike> <font color="grey">
                
                
                Sep 3 (Fri), 2021
              </td>
            </tr>
<!--
            <tr><td>Test Data Ready</td>
              <td>
                 <strike> <font color="grey">
                
                
                Dec 3 (Fri), 2021
              </td>
            </tr>
-->
            <tr><td>Evaluation Start</td>
              <td>
                 <strike> <font color="grey">
                
                
                Jan 24 (Mon), 2022
              </td>
            </tr>
            <tr><td>Evaluation End</td>
              <td>
                 <strike> <font color="grey">
                
                
                Jan 30 (Sun), 2022
              </td>
            </tr>
<!--
            <tr><td>Results Posted</td>
              <td>
                 <strike> <font color="grey">
                
                
                Mar 18 (Wed), 2020
              </td>
            </tr>
-->
            <tr><td>System Description Paper Submission Due</td>
              <td>
                 <strike> <font color="grey">
                
                
                Feb 28 (Mon), 2022
              </td>
            </tr>
<!--
            <tr><td>Task Description Paper Submission Due</td>
              <td>
                 <strike> <font color="grey">
                
                
                May 8 (Fri), 2020
              </td>
            </tr>
-->
            <tr><td>Notification to Authors</td>
              <td>
                 <strike> <font color="grey">
                
                
                Mar 31 (Thu), 2022
              </td>
            </tr>
            
            <tr><td>Camera-ready Due</td>
              <td>
                
                
                
                Apr 21 (Thu), 2022
                
              </td>
            </tr>
            <tr><td>Workshop</td>
              <td>14-15 July 2022 co-located with <a href="https://2022.naacl.org/" target="_blank">NAACL</a></td>
            </tr>

            <tr>
              <!-- <p align="center"><small>* <em>All deadlines are <a href="https://www.timeanddate.com/time/zones/aoe">AoE</a><mark>11:59PM (GMT-12)</mark>.</em></small></p> -->
              <p align="center"><small>* <em>All deadlines are calculated at 11:59 pm <br> UTC-12 hours</em></small></p>
            </tr>
          </tbody></table>
          </font><br>

        
      </div>
      <!-- ===================================== -->
      <p><mark>The competition is over. The <a href="/dataset" target="_blank">dataset</a> is publicly available. You can check out the post-evaluation phase <a href="https://competitions.codalab.org/competitions/36425" target="_blank">here</a>.</mark></p>

<h2 id="1-how-to-participate">1. How to Participate</h2>
<ul>
  <li>The organizers have defined a task (i.e., NER) and released the training data on September 3rd. The task is divided across several languages as subtasks. The participants can work on as many as languages they want to.</li>
  <li>Participants can form a team with multiple people or single person team is okay.</li>
  <li>The participants can access the training data after filling the form in the <a href="/dataset" target="_blank">Dataset</a> page.</li>
  <li>The participants can experiment with the training data to develop models. Usage of any external data or resource is allowed and highly encouraged. This process can run till the evaluation period.</li>
  <li><strong>Evaluation period</strong>: On January 24th, the organizers will release the test set containing instances without the labels. The participants will use their developed models to predict the labels for the instances and they have to create a submission file that follows exactly the same format of the training data. These prediction files should be submitted to Codalab submission portal (will be announced later). These predictions will be compared against the ground truth labels of the test data and the teams will be ranked on a leaderboard according to the performance score.</li>
  <li>Each team is encouraged to write a system description paper describing their submission system, analysis of their results, interesting insights and submit before around February 23rd, 2022. Paper submission procedure will be announced later. After a review period, each team has to update their submitted paper based on the review feedback and submit the camera ready version. Accepted papers will be published as part of the proceedings of <a href="https://semeval.github.io" target="_blank">SemEval 2022 Workshop</a>.</li>
  <li>To connect with the organizers or other participants about any questions or discussions, participants can join the <a href="https://join.slack.com/t/multiconer/shared_invite/zt-vi3g97cx-MpqTvS07XX22S78nRC2s0Q" target="_blank">Slack</a> and Google group.</li>
</ul>

<h2 id="2-training-data-format">2. Training Data Format</h2>
<p><a href="data/semeval_2021_task_11_trial_data.txt" download="">Click here to download a small set of trial data in English.</a></p>

<p>We will follow the <a href="https://universaldependencies.org/docs/format.html">CoNLL</a> format for the datasets. Here is an example data sample from the trial data.</p>

<p><img src="/images/trial_data_sample.png" alt="." /></p>

<p>In a data file, samples are separated by blank lines. Each data instance is tokenized and each line contains a single token with the associated label in the last (4th) column. Second and third columns (<code class="language-plaintext highlighter-rouge">_</code>) are ignored. Entities are labeled using the <a href="https://natural-language-understanding.fandom.com/wiki/Named_entity_recognition#BIO">BIO</a> scheme. That means, a token tagged as <code class="language-plaintext highlighter-rouge">O</code> is not part of an entity, <code class="language-plaintext highlighter-rouge">B-X</code> means the token is the first token of an <code class="language-plaintext highlighter-rouge">X</code> entity, <code class="language-plaintext highlighter-rouge">I-X</code> means the token is in the boundary (but not the first token) of an <code class="language-plaintext highlighter-rouge">X</code> type entity having multiple tokens. In the given example, the input text is:</p>

<blockquote>
  <p>the original ferrari daytona replica driven by don johnson in miami vice</p>
</blockquote>

<p>The following image shows the entities as annotated.
<img src="/images/trial_sample_viz.png" alt="." /></p>

<p>Here are some examples from the other languages.</p>
<ul>
  <li><span style="color:#274277"><b>Bangla:</b></span> <img src="/images/b/BN.png" alt="." /></li>
  <li><span style="color:#274277"><b>Chinese:</b></span><img src="/images/b/ZH.png" alt="." /></li>
  <li><span style="color:#274277"><b>Hindi:</b></span><img src="/images/b/HI.png" alt="." /></li>
  <li><span style="color:#274277"><b>Korean:</b></span><img src="/images/b/KO.png" alt="." /></li>
  <li><span style="color:#274277"><b>German:</b></span> <img src="/images/b/DE.png" alt="." /></li>
  <li><span style="color:#274277"><b>Russian:</b></span><img src="/images/b/RU.png" alt="." /></li>
  <li><span style="color:#274277"><b>Turkish:</b></span><img src="/images/b/TR.png" alt="." /></li>
  <li><span style="color:#274277"><b>Farsi:</b></span><img src="/images/b/FA.png" alt="." /></li>
  <li><span style="color:#274277"><b>Dutch:</b></span><img src="/images/b/NL.png" alt="." /></li>
  <li><span style="color:#274277"><b>Spanish:</b></span> <img src="/images/b/ES.png" alt="." /></li>
</ul>

<!--## Official Competition Metric for the Task-->

<h2 id="3-label-space">3. Label Space</h2>
<p>In this task, we focus on the following six entity types:</p>
<ol>
  <li><strong>PER</strong> : Person</li>
  <li><strong>LOC</strong> : Location</li>
  <li><strong>GRP</strong> : Group</li>
  <li><strong>CORP</strong> : Corporation</li>
  <li><strong>PROD</strong> : Product</li>
  <li><strong>CW</strong>: Creative Work</li>
</ol>

<h2 id="4-evaluation">4. Evaluation</h2>
<p>In this shared task, we provide train/dev/test data for 11 languages. Additionally, we provide dev and test sets for <a href="https://en.wikipedia.org/wiki/Code-mixing" target="_blank">code-mixed language</a> (Find relevant resources in Section 6). As a summary, we provide 11 training files and 12 dev/test files. This codalab competition is in practice phase, where you are allowed to submit prediction file for dev sets. The evaluation framework is divided in three broad tracks.</p>
<ol>
  <li>
    <p><strong>Multi-lingual (Track 1)</strong>: In this track, the participants have to train a single multi-lingual NER model using training data for all the languages. This model should be used to generate prediction files for each of the 11 languages’ evaluation (dev/test) set and a code-mixed evaluation set. That means the model should be able to handle monolingual data from any of the languages and code-mixed cases as well.<br />
<span style="color:red">Predictions from any <strong>mono-lingual</strong> model is not allowed in this track. Therefore, please do not submit predictions from mono-lingual models in this track.</span>.</p>
  </li>
  <li>
    <p><strong>Mono-lingual (Tack 2-12)</strong>: In this track, the participants have to train a model that works for only one language. For each language, there will be one dev/test set that contains examples for that particular language. Participants have to train a mono-lingual model for the language of their interest and use that to create prediction file for the evaluation set of that language.<br />
<span style="color:red">Predictions from any <strong>multi-lingual</strong> model is not allowed in this track.</span></p>
  </li>
  <li>
    <p><strong>Code-mixed (Tack 13)</strong>: This test data contains have code-mixed samples. These samples will include tokens from any of the 11 mentioned languages in the shared task. This is an additional test set apart from the 11 mono-lingual test sets.</p>
  </li>
</ol>

<h2 id="5-submission-instructions">5. Submission Instructions</h2>
<p>The evaluation script is based on <a href="https://github.com/chakki-works/seqeval/blob/master/tests/conlleval.pl">conlleval.pl</a>.</p>
<h3 id="51-format-of-prediction-file">5.1. Format of prediction file</h3>
<p>The prediction file should follow <a href="https://universaldependencies.org/format.html">CoNLL</a> format but only contain tags. That means, each line contains only the predicted tags of the tokens and sentences are separated by a blank line. Make sure your tags in your prediction file are exactly aligned with the provide dev/test sets.  For example,</p>
<ul>
  <li>Given <code class="language-plaintext highlighter-rouge">en_dev.conll</code> or <code class="language-plaintext highlighter-rouge">en_test.conll</code>
    <ul>
      <li>
        <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># id f423a88e-02b7-4d61-a546-4a1bd89cfa15    domain=dev
  it _ _ _
  originally _ _ _
  operated _ _ _
  seven _ _ _
  bus _ _ _
  routes _ _ _
  which _ _ _
  were _ _ _
  mainly _ _ _
  supermarket _ _ _
  routes _ _ _
  for _ _ _
  asda _ _ _
  and _ _ _
  tesco _ _ _
  . _ _ _
        
  ...
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
  <li>You will need generate the prediction file <code class="language-plaintext highlighter-rouge">en.pred.conll</code> in the follow format
    <ul>
      <li>
        <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  #(You can either delete sentence id or keep it)
  O
  O
  O
  O
  O
  O
  O
  O
  O
  O
  O
  O
  B-CORP
  O
  B-CORP
  O
        
  ...
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
</ul>

<h3 id="52-prepare-submission-files">5.2. Prepare submission files</h3>
<p>Follow the below instructions to submit your prediction files for a track. Codalab requires all submissions in zip format</p>

<ul>
  <li>Use your trained model to generate a prediction file for a specific tack and name it in this format: <code class="language-plaintext highlighter-rouge">&lt;language_code&gt;.pred.conll</code>.
    <ul>
      <li>For example, when you participate in the English track, you will need to generate a prediction file for en_dev.conll (or en_test.conll in the testing phase) and name it as en.pred.conll.</li>
      <li>The language_code values for  <strong>Track 12 Multilingual</strong> and <strong>Track 13 code mixed</strong> are <strong>multi</strong> and <strong>mix</strong>, respectively. That means, you will need to name the prediction file as <code class="language-plaintext highlighter-rouge">multi.pred.conll</code> or <code class="language-plaintext highlighter-rouge">mix.pred.conll</code>.</li>
    </ul>
  </li>
  <li>Compress the <code class="language-plaintext highlighter-rouge">&lt;language_code&gt;.pred.conll</code> file to a zip file by using zip <code class="language-plaintext highlighter-rouge">my_submission.zip &lt;language_code&gt;.pred.conll</code> (or your favorite zip utility), and the submit the zip file to the right track on Codalab.</li>
</ul>

<h2 id="6-some-resources-for-the-beginners-in-nlp">6. Some Resources for the Beginners in NLP</h2>
<ul>
  <li><a href="https://en.wikipedia.org/wiki/Named-entity_recognition" target="_blank">Wikipedia article on Named Entity Recognition</a></li>
  <li><a href="https://www.youtube.com/watch?v=MY9fs1Plh_o" target="_blank">Lecture from Prof. Chris Manning on the Evaluation of Named Entity Recognition</a></li>
  <li><a href="https://www.geeksforgeeks.org/python-named-entity-recognition-ner-using-spacy" target="_blank">Named Entity Recognition (NER) using spaCy in Python</a></li>
  <li><a href="https://medium.com/analytics-vidhya/custom-named-entity-recognition-ner-model-with-spacy-3-in-four-steps-7e903688d51" target="_blank">Custom Named Entity Recognition (NER) model with spaCy 3 in Four Steps</a></li>
  <li><a href="https://keras.io/examples/nlp/ner_transformers" target="_blank">Named Entity Recognition using Transformers with Keras</a></li>
  <li><a href="https://cs230.stanford.edu/blog/namedentity" target="_blank">Named Entity Recognition Tagging with Pytorch</a></li>
  <li><a href="https://skimai.com/how-to-fine-tune-bert-for-named-entity-recognition-ner/" target="_blank">How to Fine tune BERT for NER</a></li>
  <li><a href="http://nlpprogress.com/english/named_entity_recognition.html" target="_blank">Recent SOTA Papers for NER systems in NLP Progress</a></li>
  <li><a href="https://ritual.uh.edu/lince/home">Code Switching Leaderboard LinCE.</a></li>
  <li><a href="https://aclanthology.org/W18-3219.pdf">Named Entity Recognition on Code-Switched Data:
Overview of the CALCS 2018 Shared Task</a></li>
</ul>

<h3 id="communication">Communication</h3>
<ul>
  <li>
    <p>Join us in <a href="https://join.slack.com/t/multiconer/shared_invite/zt-vi3g97cx-MpqTvS07XX22S78nRC2s0Q" target="_blank">Slack</a></p>
  </li>
  <li>
    <p>Subscribe to the <a href="mailto:multiconer-semeval@googlegroups.com">task mailing list</a></p>
  </li>
  <li>
    <p><a href="mailto:multiconer-semeval-organizers@googlegroups.com">Contact the organizers</a></p>
  </li>
</ul>


      <footer class="site-footer">
<center>





</center>
</footer>


    </section>

  </body>
</html>
